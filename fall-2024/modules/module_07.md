# Disparate Impact

## Introduction

US employment and housing laws prohibit organizations from engaging in practices that *intentionally treat people differently based on special classes* (aka disparate impact) or *have an adverse impact on people based on their protected class* (aka disparate impact). [Protected classes](https://www.eeoc.gov/employers/small-business/3-who-protected-employment-discrimination) includes, race, color, religion, ethnicity, sex, national origin, disability status. While disparate impact may be easy to identify (e.g., favoring male candidates over female candidates), disparate impact is harder to identify since it might use a 'facially neutral' practice which could have an unjustified adverse impact on members of a protected class. As companies become more reliant on predictive models to make employment or housing decisions, it becomes important to screen these models and assess if they have a disparate impact on protected classes.

Here, we will study the model development cycle of predictive models to learn where/how biases resulting in disparate impact can arise.

## Concepts

* [Martin, Kirsten. "Excerpt from Big Data's Disparate Impact" In Ethics of Data and Analytics, pp. 303-318. Auerbach Publications, 2022.](https://wm.primo.exlibrisgroup.com/permalink/01COWM_INST/g9pr7p/alma991033870654103196)

## Cases

* [Dastin, Jeffrey. 2018. "Insight - Amazon scraps secret AI recruiting tool that showed bias against women." Reuters](https://web.archive.org/web/20181207170228/https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G)

* [Heaven, Will Douglas. 2021. "Bias isn't the only problem with credit scores—and no, AI can't help." MIT Technology Review.](https://web.archive.org/web/20240330140827/https://www.technologyreview.com/2021/06/17/1026519/racial-bias-noisy-data-credit-scores-mortgage-loans-fairness-machine-learning/)

* [Pangburn, DJ. 2019. "Schools are using software to help pick who gets in. What could go wrong?" Fast Company.](https://www.fastcompany.com/90342596/schools-are-quietly-turning-to-ai-to-help-pick-who-gets-in-what-could-go-wrong)

## In-class individual tasks

* Is hiring via algorithm fair? 
* At what stage in the development cycle was disparate impact introduced?
* What could go wrong given Barocas and Selbst’s paper?

## In-class group task

* If we were to design a project for admissions to college, how would you design it?